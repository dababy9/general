Name: Caleb Walker

Works Cited: https://www.geeksforgeeks.org/python-count-of-elements-matching-particular-condition/
Used to write a simple part of my program that counts how many mids belong to a given company within a given range

Explanation:
My program is a little bit cheesy, and performs abnormally well on cases where the companies are mostly sorted (the 'close' files). Essentially, I first map the entire list into company areas trying to maximize the number of mids already in the correct spot. First, I attempt a naive solution (to cover any of the 'close' files). Look at all possible company mappings for the first range, choose the one with the most mids already in the range, and move on to the next range. For the most part, this ensures maximum correctness prior to any swaps if the input is 'close'. Then, I randomly generate 1000 company mappings and choose the best one (if it's better than the naive solution). This works well for the more scattered inputs, because the naive solution generally isn't very optimal. Then, with a framework for how the companies should be ordered, I just use a special selection sort that doesn't use the numerical comparison of companies, but rather the generated order of companies. I also make sure that 'better' swaps (where both mids are swapped into their correct company range) happen before 'worse' swaps (only one mid is placed into their correct company range).

How I came up with solution:
The thought of using the modified selection sort came first. I realized that if I optimized the ordering of the companies before any swapping, then I could just use that ordering for selection sort rather than a numerical ordering. Then I had the problem of finding the optimal ordering of companies. I was very ambitious at first - I aimed to get THE BEST ordering (with the most mids already in the right spot). I used a recursive algorithm to run through all permutations of company orderings - however, this would end up being k!, which for 36 companies, is extremely large. I attempted memoization to alleviate duplicate calculations, but that was simply not even close to enough. I then just used a more naive way of getting the 'obvious' ordering for the 'close' inputs, and just used the power of randomness for everything else.

Runtime Analysis:
For the runtime analysis, there are more or less two parts to analyze. The first part is the ordering of the companies, and the second part is the actual swapping. The ordering is two consecutive operations: the naive ordering followed by the random ordering. The random ordering is does ~2000n operations: it does the loop 1000 times, and the loop is just randomly shuffling the list (n operations) and then checking how many mids are already place correctly (n operations). This means that the random ordering is Theta(n). The naive ordering is a bit more complex: in terms of the outer two loops, it behaves similar to selection sort - it loops through k companies, then k-1, then k-2 and so on. This ends up being O(k^2) as we have proven in class. But then, for every one of those iterations, it checks a certain range of the mids to count how many mids are correctly placed. This number, for the best case, is n/k (if all companies have the same number of mids), and at worst case, n (if one company has almost all mids). This means that when the company numbers are close to a uniform distribution, the runtime for the naive ordering is (k^2)*(n/k), or Theta(nk). When company numbers are unevenly distributed, the runtime is (k^2)*(n), or O(nk^2); a Theta bound cannot be determined, because the practical runtime depends on if the naive ordering puts the company with all the mids at the front or the back (k*n vs k+n). Finally, for the actual swapping, the program checks every mid, and if a mid is in the wrong company, it looks through all unsorted mids to find one to swap into the correct company. Worst case (no mids are in the correct company), this works just like selection sort (Theta(n^2)). However, the best case (all mids are already sorted) is Theta(n). When putting together total runtime, we can ignore the random shuffling (it is dominated by the naive ordering). We also have to look at four cases: when the company numbers are evenly/unevenly distributed, and when the mids are completely sorted/unsorted. However, due to the nature of this problem, it is impossible for the company numbers to be unevenly distributed AND all mids to be unsorted. Thus, we only need to consider three cases - 1. {unsorted mids, even distribution}; 2. {sorted mids, even distribution}; 3. {sorted mids, uneven distribution}. For 1., the runtime for naive ordering and the swapping is Theta(nk) + Theta(n^2), which is Theta(n^2 + nk). For 2., the runtime is Theta(nk) + Theta(n), which is Theta(nk). Finally, for 3., the runtime is O(nk^2) + Theta(n), which is O(nk^2) and Omega(n).

Swap Analysis:
My program is definitely bounded by O(n), as it is an improved selection sort (and thus won't ever be worse). For the lower bound, the best and worst case must be considered (list is already sorted vs. list is completely shuffled). For the best case, the number of swaps will be Theta(1), which makes sense (there shouldn't be any swaps necessary). When the list is completely unsorted, we proved in class that there must be at least n/2 swaps performed, which gives an Omega(n). So, for best case, the algorithm is O(n) and Theta(1). For worst case, the algorithm is Theta(n).